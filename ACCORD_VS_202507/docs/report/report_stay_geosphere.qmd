---
title: "Report on ACCORD VS at GeoSphere"
subtitle: "Implementation and Validation of Spatial Verification Methods for Extreme Events"
author: "Carlos Peralta, Polly Schmederer and Philipp Scheffknecht"
format: html
date: "11 August 2025"
date-modified: last-modified
###bibliography: references.bib
lang: en
---

# Introduction

During a three-week scientific visit at GeoSphere, the main focus was the **implementation and validation of spatial verification methods** for high-impact meteorological forecast assessment, 
particularly for extreme weather events. This work contributed to the ACCORD MQA initiative, targeting operational model evaluation and development.

# General Review of Verification Methods

A comprehensive review of advanced spatial verification techniques set the context for evaluating high-resolution weather forecasts, especially regarding the challenge of location-dependent forecast errors and the "double penalty" effect. Classical scores were contrasted with neighborhood-based and feature-based metrics[^review].

- **Traditional metrics:** TS (Threat Score), ETS (Equitable Threat Score).
- **Spatial metrics:** Address limitations of grid-point comparison and emphasize the importance of spatial structure[^review].

[^review]: See `general_rev/review.qmd`.

# Implementation of SLX Score

## Overview

The **SLX score** was implemented to quantify the similarity between forecast and observed fields, systematically reducing penalties for small spatial displacement errors.

- **Key properties:**
  - Focuses on matching patterns and features within spatial neighborhoods.
  - Sensitive to both the location and the structure of extreme events.
  - Effective for high-resolution forecasts where traditional point-by-point metrics fail[^slx_presentation].

## Validation Cases

Validation was performed using real-world meteorological events:

- **Case 1: Extreme precipitation event (Date/Event)**
  *Figure 1: SLX score spatial map for Case 1 validation*
  
  ![](case_studies/results_case1_SLX.png) <!-- Replace with actual path to plot from results.md or validation.qmd -->

- **Case 2: Field comparison for ensemble spread**
  *Figure 2: Histogram of SLX scores across ensemble members*

  ![](case_studies/ensemble_spread_SLX.png) <!-- Placeholder for second plot -->

*Findings:*  
SLX score provided enhanced discrimination of location errors and improved assessment of feature matching for extremes, outperforming classical methods in both sensitivity and operational utility[^slx_validation].

[^slx_presentation]: See `review_sass/slx_presentation.qmd`; `slx_presentation.pdf`
[^slx_validation]: See `review_sass/slx_validation.qmd`; `slx_validation.pdf`

# Agreement Scales Score (Dey Method)

## Method Summary

The **Agreement Scales Score** identifies the smallest neighborhood size at which forecast and observation fields "agree", mapping scale-dependent skill and uncertainty.

- **Key properties:**
  - Produces spatial maps of agreement scale.
  - Reveals local skill variations and ensemble spread.
  - Enables targeted verification of prediction uncertainty for extremes[^dey_agreement_scales_presentation].

## Validation Example

- **Case: Severe convection event**
  *Figure 3: Agreement scale map for ensemble forecasts of a convective event*

  ![](case_studies/agreement_scale_event.png) <!-- Placeholder for actual output -->

*Interpretation:*  
The agreement scale identified regions of both high and low skill, illustrating the method's capacity to diagnose event-localized ensemble forecast confidence[^agreement_scales_validation].

[^dey_agreement_scales_presentation]: See `review_dey/dey_agreement_scales_presentation.qmd`; `dey_agreement_scales_presentation.pdf`
[^agreement_scales_validation]: See `review_dey/agreement_scales_validation.qmd`; `agreement_scales_validation.pdf`

# Results and Implications for ACCORD VS

The applied methods (SLX and Agreement Scales) successfully highlighted:

- Enhanced assessment of displacement and structure errors in extreme event forecasts.
- Improved operational diagnostics for ensemble spread and model skill.
- Practical, validated algorithms for routine use in operational forecast verification, supporting both feedback and model inter-comparison.

## Summary Table: Core Methods

| Method                    | Purpose                          | Key Benefit                                         |
|---------------------------|----------------------------------|-----------------------------------------------------|
| SLX Score                 | Spatial field pattern matching   | Less penalization for small shifts, robust for extremes|
| Agreement Scales Score    | Scale-dependent skill mapping    | Local skill, uncertainty, ensemble spread visualization|

# References

Include all references from the documents. For external scientific background, see:
- Skok, G., et al. "Spatial verification of global precipitation forecasts," arXiv (2025)[1].
- Hutchison, K., et al. "Climate Cloud Model Forecast Verificationâ€”an Engineering Perspective," AEER (2020)[2].

Further internal references are embedded in the notebook via in-text citations to your documentation:

- ACCORD VS documentation:  
  - `general_rev/review.qmd`
  - `review_sass/slx_presentation.qmd` & `slx_validation.qmd`  
  - `review_dey/dey_agreement_scales_presentation.qmd` & `agreement_scales_validation.qmd`  
  - `case_studies/results.md`

---

# Appendix

## Plots and Code Snippets


